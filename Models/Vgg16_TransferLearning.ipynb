{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vgg16-TransferLearning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTUY7Av_qNOa",
        "outputId": "ce52fa29-43ec-4715-c1eb-2a5cfa6c8350"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ks8uCrPqegV"
      },
      "source": [
        "EPOCHS = 30\r\n",
        "data_dir =  '/content/drive/My Drive/Final Project/chest_xray/chest_xray'\r\n",
        "TEST = 'test'\r\n",
        "TRAIN = 'train'\r\n",
        "VAL ='val'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GluZjYagq9mk"
      },
      "source": [
        "import copy\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import pandas as pd \r\n",
        "import os\r\n",
        "import seaborn as sns\r\n",
        "import skimage\r\n",
        "from skimage import io, transform\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torchvision\r\n",
        "from torchvision import datasets, models, transforms"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2HFbZ6Xq1Gs",
        "outputId": "ebcfef3b-e89d-4b4f-c793-e1b39f335cc6"
      },
      "source": [
        "def data_transforms(phase):\r\n",
        "    if phase == TRAIN:\r\n",
        "        transform = transforms.Compose([\r\n",
        "            transforms.Resize(256),\r\n",
        "            transforms.CenterCrop(224),\r\n",
        "            transforms.ToTensor(),\r\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\r\n",
        "        ])\r\n",
        "        \r\n",
        "    if phase == VAL:\r\n",
        "        transform = transforms.Compose([\r\n",
        "            transforms.Resize(256),\r\n",
        "            transforms.CenterCrop(224),\r\n",
        "            transforms.ToTensor(),\r\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\r\n",
        "        ])\r\n",
        "    \r\n",
        "    if phase == TEST:\r\n",
        "        transform = transforms.Compose([\r\n",
        "            transforms.Resize(256),\r\n",
        "            transforms.CenterCrop(224),\r\n",
        "            transforms.ToTensor(),\r\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\r\n",
        "        ])        \r\n",
        "        \r\n",
        "    return transform\r\n",
        "\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "print(device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXjSx6F0q6JC"
      },
      "source": [
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms(x)) \r\n",
        "                  for x in [TRAIN, VAL, TEST]}\r\n",
        "\r\n",
        "dataloaders = {TRAIN: torch.utils.data.DataLoader(image_datasets[TRAIN], batch_size = 4, shuffle=True), \r\n",
        "               VAL: torch.utils.data.DataLoader(image_datasets[VAL], batch_size = 1, shuffle=True), \r\n",
        "               TEST: torch.utils.data.DataLoader(image_datasets[TEST], batch_size = 1, shuffle=True)}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrbBXJYCrEcy"
      },
      "source": [
        "dataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, VAL]}\r\n",
        "classes = image_datasets[TRAIN].classes\r\n",
        "class_names = image_datasets[TRAIN].classes"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDXRCgtOrMpY"
      },
      "source": [
        "inputs, classes = next(iter(dataloaders[TRAIN]))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pves6PuWrR0v"
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs):\r\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\r\n",
        "    best_acc = 0.0\r\n",
        "    \r\n",
        "    for epoch in range(num_epochs):\r\n",
        "        print(\"Epoch: {}/{}\".format(epoch+1, num_epochs))\r\n",
        "        print(\"=\"*10)\r\n",
        "        \r\n",
        "        for phase in [TRAIN, VAL]:\r\n",
        "            if phase == TRAIN:\r\n",
        "                scheduler.step()\r\n",
        "                model.train()\r\n",
        "            else:\r\n",
        "                model.eval()\r\n",
        "            running_loss = 0.0\r\n",
        "            running_corrects = 0\r\n",
        "            for data in dataloaders[phase]:\r\n",
        "                inputs, labels = data\r\n",
        "                inputs = inputs.to(device)\r\n",
        "                labels = labels.to(device)\r\n",
        "                optimizer.zero_grad()\r\n",
        "                with torch.set_grad_enabled(phase==TRAIN):\r\n",
        "                    outputs = model(inputs)\r\n",
        "                    _, preds = torch.max(outputs, 1)\r\n",
        "                    loss = criterion(outputs, labels)\r\n",
        "                    if phase == 'train':\r\n",
        "                        loss.backward()\r\n",
        "                        optimizer.step()\r\n",
        "                running_loss += loss.item() * inputs.size(0)\r\n",
        "                running_corrects += torch.sum(preds == labels.data)\r\n",
        "\r\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\r\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\r\n",
        "\r\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\r\n",
        "                phase, epoch_loss, epoch_acc))\r\n",
        "\r\n",
        "            if phase == 'val' and epoch_acc > best_acc:\r\n",
        "                best_acc = epoch_acc\r\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\r\n",
        "\r\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\r\n",
        "    model.load_state_dict(best_model_wts)\r\n",
        "    return model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuy7N8LkrUu7"
      },
      "source": [
        "model_pre = models.vgg16()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5luJ312MrXzD",
        "outputId": "298e71ec-84c9-4669-b3f4-3f29508f65e0"
      },
      "source": [
        "for param in model_pre.features.parameters():\r\n",
        "    param.required_grad = False\r\n",
        "\r\n",
        "num_features = model_pre.classifier[6].in_features\r\n",
        "features = list(model_pre.classifier.children())[:-1] \r\n",
        "features.extend([nn.Linear(num_features, len(class_names))])\r\n",
        "model_pre.classifier = nn.Sequential(*features) \r\n",
        "print(model_pre)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Upf4KNP6raVH"
      },
      "source": [
        "model_pre = model_pre.to(device)\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.SGD(model_pre.parameters(), lr=0.001, momentum=0.9, weight_decay=0.01)\r\n",
        "# Decay LR by a factor of 0.1 every 10 epochs\r\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szfRGfMVrc8A",
        "outputId": "b9547dd9-e27b-40cc-cc18-b6d566247c05"
      },
      "source": [
        "model_pre = train_model(model_pre, criterion, optimizer, exp_lr_scheduler, num_epochs=EPOCHS)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/30\n",
            "==========\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.2835 Acc: 0.8859\n",
            "val Loss: 0.8969 Acc: 0.5000\n",
            "Epoch: 2/30\n",
            "==========\n",
            "train Loss: 0.1398 Acc: 0.9493\n",
            "val Loss: 1.3703 Acc: 0.5625\n",
            "Epoch: 3/30\n",
            "==========\n",
            "train Loss: 0.1153 Acc: 0.9596\n",
            "val Loss: 0.8176 Acc: 0.7500\n",
            "Epoch: 4/30\n",
            "==========\n",
            "train Loss: 0.1122 Acc: 0.9604\n",
            "val Loss: 0.4598 Acc: 0.8125\n",
            "Epoch: 5/30\n",
            "==========\n",
            "train Loss: 0.1026 Acc: 0.9615\n",
            "val Loss: 0.4827 Acc: 0.8125\n",
            "Epoch: 6/30\n",
            "==========\n",
            "train Loss: 0.0955 Acc: 0.9657\n",
            "val Loss: 0.4274 Acc: 0.8750\n",
            "Epoch: 7/30\n",
            "==========\n",
            "train Loss: 0.0953 Acc: 0.9665\n",
            "val Loss: 0.5957 Acc: 0.6875\n",
            "Epoch: 8/30\n",
            "==========\n",
            "train Loss: 0.0940 Acc: 0.9671\n",
            "val Loss: 0.6810 Acc: 0.7500\n",
            "Epoch: 9/30\n",
            "==========\n",
            "train Loss: 0.0917 Acc: 0.9686\n",
            "val Loss: 0.5964 Acc: 0.7500\n",
            "Epoch: 10/30\n",
            "==========\n",
            "train Loss: 0.0644 Acc: 0.9753\n",
            "val Loss: 0.5722 Acc: 0.7500\n",
            "Epoch: 11/30\n",
            "==========\n",
            "train Loss: 0.0641 Acc: 0.9768\n",
            "val Loss: 0.5404 Acc: 0.7500\n",
            "Epoch: 12/30\n",
            "==========\n",
            "train Loss: 0.0626 Acc: 0.9784\n",
            "val Loss: 0.8173 Acc: 0.6250\n",
            "Epoch: 13/30\n",
            "==========\n",
            "train Loss: 0.0613 Acc: 0.9776\n",
            "val Loss: 0.4810 Acc: 0.7500\n",
            "Epoch: 14/30\n",
            "==========\n",
            "train Loss: 0.0592 Acc: 0.9795\n",
            "val Loss: 0.5615 Acc: 0.6875\n",
            "Epoch: 15/30\n",
            "==========\n",
            "train Loss: 0.0582 Acc: 0.9789\n",
            "val Loss: 0.5564 Acc: 0.7500\n",
            "Epoch: 16/30\n",
            "==========\n",
            "train Loss: 0.0592 Acc: 0.9797\n",
            "val Loss: 0.6525 Acc: 0.6250\n",
            "Epoch: 17/30\n",
            "==========\n",
            "train Loss: 0.0586 Acc: 0.9791\n",
            "val Loss: 0.5563 Acc: 0.7500\n",
            "Epoch: 18/30\n",
            "==========\n",
            "train Loss: 0.0545 Acc: 0.9791\n",
            "val Loss: 0.6391 Acc: 0.6250\n",
            "Epoch: 19/30\n",
            "==========\n",
            "train Loss: 0.0561 Acc: 0.9812\n",
            "val Loss: 0.6087 Acc: 0.7500\n",
            "Epoch: 20/30\n",
            "==========\n",
            "train Loss: 0.0535 Acc: 0.9812\n",
            "val Loss: 0.6175 Acc: 0.6875\n",
            "Epoch: 21/30\n",
            "==========\n",
            "train Loss: 0.0527 Acc: 0.9816\n",
            "val Loss: 0.6321 Acc: 0.6250\n",
            "Epoch: 22/30\n",
            "==========\n",
            "train Loss: 0.0505 Acc: 0.9828\n",
            "val Loss: 0.6580 Acc: 0.6250\n",
            "Epoch: 23/30\n",
            "==========\n",
            "train Loss: 0.0515 Acc: 0.9824\n",
            "val Loss: 0.5963 Acc: 0.6875\n",
            "Epoch: 24/30\n",
            "==========\n",
            "train Loss: 0.0518 Acc: 0.9824\n",
            "val Loss: 0.6056 Acc: 0.6875\n",
            "Epoch: 25/30\n",
            "==========\n",
            "train Loss: 0.0500 Acc: 0.9832\n",
            "val Loss: 0.6647 Acc: 0.6250\n",
            "Epoch: 26/30\n",
            "==========\n",
            "train Loss: 0.0501 Acc: 0.9822\n",
            "val Loss: 0.5512 Acc: 0.6875\n",
            "Epoch: 27/30\n",
            "==========\n",
            "train Loss: 0.0509 Acc: 0.9832\n",
            "val Loss: 0.5830 Acc: 0.6875\n",
            "Epoch: 28/30\n",
            "==========\n",
            "train Loss: 0.0501 Acc: 0.9835\n",
            "val Loss: 0.5696 Acc: 0.6875\n",
            "Epoch: 29/30\n",
            "==========\n",
            "train Loss: 0.0510 Acc: 0.9828\n",
            "val Loss: 0.5513 Acc: 0.6875\n",
            "Epoch: 30/30\n",
            "==========\n",
            "train Loss: 0.0477 Acc: 0.9851\n",
            "val Loss: 0.5704 Acc: 0.6875\n",
            "Best val Acc: 0.875000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQl0h9U-reyc"
      },
      "source": [
        "def test_model():\r\n",
        "    running_correct = 0.0\r\n",
        "    running_total = 0.0\r\n",
        "    true_labels = []\r\n",
        "    pred_labels = []\r\n",
        "    with torch.no_grad():\r\n",
        "        for data in dataloaders[TEST]:\r\n",
        "            inputs, labels = data\r\n",
        "            inputs = inputs.to(device)\r\n",
        "            labels = labels.to(device)\r\n",
        "            true_labels.append(labels.item())\r\n",
        "            outputs = model_pre(inputs)\r\n",
        "            _, preds = torch.max(outputs.data, 1)\r\n",
        "            pred_labels.append(preds.item())\r\n",
        "            running_total += labels.size(0)\r\n",
        "            running_correct += (preds == labels).sum().item()\r\n",
        "        acc = running_correct/running_total\r\n",
        "    return (true_labels, pred_labels, running_correct, running_total, acc)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGiN0LFXrkVu"
      },
      "source": [
        "true_labels, pred_labels, running_correct, running_total, acc = test_model()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqcUBLRdrpay",
        "outputId": "e3fdbfdd-01ff-4f79-f7e0-2bebe815d79e"
      },
      "source": [
        "print(\"Total Correct: {}, Total Test Images: {}\".format(running_correct, running_total))\r\n",
        "print(\"Test Accuracy: \", acc)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Correct: 507.0, Total Test Images: 624.0\n",
            "Test Accuracy:  0.8125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "P1Aa_cQqscNn",
        "outputId": "5eb24430-d019-4a66-812a-0fbd8ad33cc5"
      },
      "source": [
        "cm = confusion_matrix(true_labels, pred_labels)\r\n",
        "tn, fp, fn, tp = cm.ravel()\r\n",
        "ax = sns.heatmap(cm, annot=True, fmt=\"d\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGpkY03rsqKW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}